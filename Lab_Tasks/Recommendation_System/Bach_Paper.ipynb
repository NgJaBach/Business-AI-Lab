{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "class uuCF(object):\n",
    "    \"\"\"\n",
    "    User-User Collaborative Filtering implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Y_data: np.ndarray, k: int = 40, sim_func=cosine_similarity):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        Args:\n",
    "            Y_data (np.ndarray): A 2D array of shape (n_samples, 3) where each row is [user_id, item_id, rating].\n",
    "            k (int): The number of nearest neighbors to consider.\n",
    "            sim_func (function): Similarity function to compute user-user similarity (default: cosine_similarity).\n",
    "        \"\"\"\n",
    "\n",
    "        self.Y_data = Y_data # User-item interaction data\n",
    "        self.k = k # Number of neighbors\n",
    "        self.sim_func = sim_func # Similarity function\n",
    "        self.Ybar = None # Normalized rating data\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1 # Number of users\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1 # Number of items\n",
    "        self.mu = None  # User mean ratings\n",
    "        self.S = None  # User-user similarity matrix\n",
    "    \n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Prepares the data by normalizing the ratings, creating a sparse matrix, and computing the similarity matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract user IDs from data\n",
    "        users = self.Y_data[:, 0]\n",
    "\n",
    "        # Copy and normalize the ratings\n",
    "        self.Ybar = self.Y_data.copy()\n",
    "        self.mu = np.zeros(self.n_users)\n",
    "\n",
    "        # Compute mean rating for each user\n",
    "        self.mu = np.bincount(users.astype(int), weights=self.Y_data[:, 2]) / np.bincount(users.astype(int))\n",
    "        self.mu = np.nan_to_num(self.mu) # Replace NaNs with 0 for users with no ratings\n",
    "\n",
    "        # Normalize ratings by subtracting user means\n",
    "        self.Ybar[:, 2] = self.Y_data[:, 2] - self.mu[users.astype(int)]\n",
    "\n",
    "        # Create a sparse matrix representation of the normalized ratings\n",
    "        self.Ybar = sparse.coo_matrix(\n",
    "            (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])),\n",
    "            shape=(self.n_items, self.n_users)\n",
    "        ).tocsr()\n",
    "        \n",
    "        # Compute user-user similarity matrix\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def predict_rating(self, user_id: int, item_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Predict the rating of a specific user for a specific item.\n",
    "        Args:\n",
    "            user_id (int): ID of the user.\n",
    "            item_id (int): ID of the item.\n",
    "        Returns:\n",
    "            float: Predicted rating for the given user and item.\n",
    "        \"\"\"\n",
    "        # Find all users who rated the target item\n",
    "        item_ids = np.where(self.Y_data[:, 1] == item_id)[0].astype(int)\n",
    "        users_rated_item = self.Y_data[item_ids, 0].astype(int)\n",
    "\n",
    "        # Similarity of the target user with users who rated the item\n",
    "        sim_scores = self.S[user_id, users_rated_item]\n",
    "\n",
    "        # Get the k most similar users\n",
    "        nearest_neighbors = np.argsort(sim_scores)[-self.k:]  # Top-k similarities\n",
    "        nearest_sim_scores = sim_scores[nearest_neighbors]  # Similarities of nearest neighbors\n",
    "        ratings_by_neighbors = self.Ybar[item_id, users_rated_item[nearest_neighbors]]  # Ratings by neighbors\n",
    "\n",
    "        # Compute weighted average prediction\n",
    "        eps = 1e-8  # Small number to avoid division by zero\n",
    "        prediction = (ratings_by_neighbors * nearest_sim_scores).sum() / (np.abs(nearest_sim_scores).sum() + eps)\n",
    "\n",
    "        # Add the user's mean rating back\n",
    "        return prediction + self.mu[user_id]\n",
    "    \n",
    "    def recommend(self, user_id, top_k=10, candidates=None):\n",
    "        \"\"\"\n",
    "        Recommend top-k items for a given user.\n",
    "        \n",
    "        Args:\n",
    "            user_id (int): Target user ID.\n",
    "            top_k (int): Number of items to recommend.\n",
    "            candidates (list or None): Pre-generated candidate items.\n",
    "            \n",
    "        Returns:\n",
    "            list: List of recommended item IDs.\n",
    "        \"\"\"\n",
    "\n",
    "        # Use all items as candidates if none are provided\n",
    "        if candidates is None:\n",
    "            candidates = range(self.n_items)\n",
    "\n",
    "        # Predict ratings for all candidate items\n",
    "        predictions = [(item, self.predict_rating(user_id, item)) for item in candidates]\n",
    "\n",
    "        # Sort items by predicted ratings and return the top-k\n",
    "        predictions = sorted(predictions, key=lambda x: x[1], reverse=True)\n",
    "        return [item[0] for item in predictions[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating base:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1         1       5       874965758\n",
      "1        1         2       3       876893171\n",
      "2        1         3       4       878542960\n",
      "3        1         4       3       876893119\n",
      "4        1         5       3       889751712 \n",
      "\n",
      "Rating test:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1        20       4       887431883\n",
      "1        1        33       4       878542699\n",
      "2        1        61       4       878542420\n",
      "3        1       117       3       874965739\n",
      "4        1       155       2       878542201 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "rating_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols)\n",
    "rating_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Rating base:\\n', rating_base.head(), '\\n')\n",
    "print('Rating test:\\n', rating_test.head(), '\\n')\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "rate_train = rating_base.to_numpy()\n",
    "rate_test = rating_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running User-User Collaborative Filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating HR@10 with candidates:   6%|â–Œ         | 582/9430 [00:09<02:30, 58.80test/s]"
     ]
    }
   ],
   "source": [
    "def generate_candidates(user_id, user_similarity, Y_data, top_k_users=10, top_k_items=20):\n",
    "    \"\"\"\n",
    "    Generate candidate items for a given user based on user similarity.\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): Target user ID.\n",
    "        user_similarity (np.ndarray): User-user similarity matrix.\n",
    "        Y_data (np.ndarray): Interaction data (user_id, item_id, rating).\n",
    "        top_k_users (int): Number of similar users to consider.\n",
    "        top_k_items (int): Number of top items to select as candidates.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of candidate item IDs.\n",
    "    \"\"\"\n",
    "    # Get the indices of the top-k similar users\n",
    "    similar_users = np.argsort(user_similarity[user_id])[-top_k_users:]\n",
    "\n",
    "    # Collect items rated by these users\n",
    "    candidate_items = {}\n",
    "    for sim_user in similar_users:\n",
    "        user_items = Y_data[Y_data[:, 0] == sim_user, 1]  # Items rated by the similar user\n",
    "        for item in user_items:\n",
    "            if item not in candidate_items:\n",
    "                candidate_items[item] = 0\n",
    "            candidate_items[item] += 1  # Count frequency of each item\n",
    "\n",
    "    # Sort items by frequency and return the top-k items\n",
    "    sorted_candidates = sorted(candidate_items.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [item[0] for item in sorted_candidates[:top_k_items]]\n",
    "\n",
    "# Transform user and item indices to start from 0 (required for matrix operations)\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Train and evaluate User-User Collaborative Filtering\n",
    "print(\"Running User-User Collaborative Filtering...\")\n",
    "rs = uuCF(rate_train, k=40)\n",
    "rs.fit()\n",
    "\n",
    "# Calculate HR@10 for User-User CF with candidate generation\n",
    "hits = 0\n",
    "for n in tqdm(range(rate_test.shape[0]), desc=\"Calculating HR@10 with candidates\", unit=\"test\"):\n",
    "    user_id = int(rate_test[n, 0])\n",
    "    ground_truth_item = int(rate_test[n, 1])\n",
    "\n",
    "    # Generate candidate items for the user\n",
    "    candidates = generate_candidates(user_id, rs.S, rate_train)\n",
    "\n",
    "    # Get recommendations for the user (only from candidates)\n",
    "    recommendations = rs.recommend(user_id, top_k=10, candidates=candidates)\n",
    "\n",
    "    # Check if the ground truth item is in the recommendations\n",
    "    if ground_truth_item in recommendations:\n",
    "        hits += 1\n",
    "\n",
    "HR_10 = hits / rate_test.shape[0]\n",
    "print(f'User-User CF, HR@10 = {HR_10}')\n",
    "\n",
    "# Calculate RMSE for User-User CF\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0  # Squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.predict_rating(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2]) ** 2\n",
    "\n",
    "RMSE = np.sqrt(SE / n_tests)\n",
    "print(f'User-User CF, RMSE = {RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_item_based(user_id, item_similarity, Y_data, top_k_items=20):\n",
    "    \"\"\"\n",
    "    Generate candidate items for a given user based on item similarity.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): Target user ID.\n",
    "        item_similarity (np.ndarray): Item-item similarity matrix.\n",
    "        Y_data (np.ndarray): Interaction data (user_id, item_id, rating).\n",
    "        top_k_items (int): Number of top items to select as candidates.\n",
    "\n",
    "    Returns:\n",
    "        list: List of candidate item IDs.\n",
    "    \"\"\"\n",
    "    # Get items rated by the user\n",
    "    user_items = Y_data[Y_data[:, 0] == user_id, 1]  # Items the user has interacted with\n",
    "\n",
    "    candidate_items = {}\n",
    "    for item in user_items:  # Iterate over each item the user has interacted with\n",
    "        # Get top-k similar items for the current item\n",
    "        similar_items = np.argsort(item_similarity[item])[-top_k_items:]\n",
    "\n",
    "        for sim_item in similar_items:\n",
    "            if sim_item not in user_items:  # Avoid items already rated by the user\n",
    "                if sim_item not in candidate_items:\n",
    "                    candidate_items[sim_item] = 0\n",
    "                candidate_items[sim_item] += 1  # Count frequency of each item\n",
    "\n",
    "    # Sort items by frequency and return as candidates\n",
    "    sorted_candidates = sorted(candidate_items.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [item[0] for item in sorted_candidates[:top_k_items]]\n",
    "\n",
    "# Transform data for Item-Item CF by swapping user_id and item_id\n",
    "print(\"\\nRunning Item-Item Collaborative Filtering...\")\n",
    "rate_train = rate_train[:, [1, 0, 2]]\n",
    "rate_test = rate_test[:, [1, 0, 2]]\n",
    "\n",
    "# Reuse the same uuCF class for Item-Item CF\n",
    "rs = uuCF(rate_train, k=40)\n",
    "rs.fit()\n",
    "\n",
    "# Calculate HR@10 for Item-Item CF with candidate generation\n",
    "hits = 0\n",
    "for n in tqdm(range(rate_test.shape[0]), desc=\"Calculating HR@10 with candidates (Item-Item CF)\", unit=\"test\"):\n",
    "    item_id = int(rate_test[n, 1])  # Column interpretation after swapping\n",
    "    ground_truth_user = int(rate_test[n, 0])\n",
    "\n",
    "    # Generate candidate items for the user\n",
    "    candidates = generate_candidates_item_based(user_id, rs.S, rate_train)\n",
    "\n",
    "    # Get recommendations for the user (only from candidates)\n",
    "    recommendations = rs.recommend(user_id, top_k=10, candidates=candidates)\n",
    "\n",
    "    # Check if the ground truth item is in the recommendations\n",
    "    if ground_truth_item in recommendations:\n",
    "        hits += 1\n",
    "\n",
    "HR_10 = hits / rate_test.shape[0]\n",
    "print(f'Item-Item CF, HR@10 = {HR_10}')\n",
    "\n",
    "\n",
    "# Calculate RMSE for Item-Item CF\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.predict_rating(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2]) ** 2\n",
    "\n",
    "RMSE = np.sqrt(SE / n_tests)\n",
    "print(f'Item-Item CF, RMSE = {RMSE}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
