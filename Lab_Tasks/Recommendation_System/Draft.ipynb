{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "class uuCF(object):\n",
    "    \"\"\"\n",
    "    User-User Collaborative Filtering implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Y_data: np.ndarray, k: int = 40, sim_func=cosine_similarity):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        Args:\n",
    "            Y_data (np.ndarray): A 2D array of shape (n_samples, 3) where each row is [user_id, item_id, rating].\n",
    "            k (int): The number of nearest neighbors to consider.\n",
    "            sim_func (function): Similarity function to compute user-user similarity (default: cosine_similarity).\n",
    "        \"\"\"\n",
    "\n",
    "        self.Y_data = Y_data # User-item interaction data\n",
    "        self.k = k # Number of neighbors\n",
    "        self.sim_func = sim_func # Similarity function\n",
    "        self.Ybar = None # Normalized rating data\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1 # Number of users\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1 # Number of items\n",
    "        self.mu = None  # User mean ratings\n",
    "        self.S = None  # User-user similarity matrix\n",
    "    \n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Prepares the data by normalizing the ratings, creating a sparse matrix, and computing the similarity matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract user IDs from data\n",
    "        users = self.Y_data[:, 0]\n",
    "\n",
    "        # Copy and normalize the ratings\n",
    "        self.Ybar = self.Y_data.copy()\n",
    "        self.mu = np.zeros(self.n_users)\n",
    "\n",
    "        # Compute mean rating for each user\n",
    "        self.mu = np.bincount(users.astype(int), weights=self.Y_data[:, 2]) / np.bincount(users.astype(int))\n",
    "        self.mu = np.nan_to_num(self.mu) # Replace NaNs with 0 for users with no ratings\n",
    "\n",
    "        # Normalize ratings by subtracting user means\n",
    "        self.Ybar[:, 2] = self.Y_data[:, 2] - self.mu[users.astype(int)]\n",
    "\n",
    "        # Create a sparse matrix representation of the normalized ratings\n",
    "        self.Ybar = sparse.coo_matrix(\n",
    "            (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])),\n",
    "            shape=(self.n_items, self.n_users)\n",
    "        ).tocsr()\n",
    "        \n",
    "        # Compute user-user similarity matrix\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def predict_rating(self, user_id: int, item_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Predict the rating of a specific user for a specific item.\n",
    "        Args:\n",
    "            user_id (int): ID of the user.\n",
    "            item_id (int): ID of the item.\n",
    "        Returns:\n",
    "            float: Predicted rating for the given user and item.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Find all users who rated the target item\n",
    "        item_ids = np.where(self.Y_data[:, 1] == item_id)[0].astype(int)\n",
    "        users_rated_item = self.Y_data[item_ids, 0].astype(int)\n",
    "\n",
    "        # Similarity of the target user with users who rated the item\n",
    "        sim_scores = self.S[user_id, users_rated_item]\n",
    "\n",
    "        # Get the k most similar users\n",
    "        nearest_neighbors = np.argsort(sim_scores)[-self.k:]  # Top-k similarities\n",
    "        nearest_sim_scores = sim_scores[nearest_neighbors]  # Similarities of nearest neighbors\n",
    "        ratings_by_neighbors = self.Ybar[item_id, users_rated_item[nearest_neighbors]]  # Ratings by neighbors\n",
    "\n",
    "        # Compute weighted average prediction\n",
    "        eps = 1e-8  # Small number to avoid division by zero\n",
    "        prediction = (ratings_by_neighbors * nearest_sim_scores).sum() / (np.abs(nearest_sim_scores).sum() + eps)\n",
    "\n",
    "        # Add the user's mean rating back\n",
    "        return prediction + self.mu[user_id]\n",
    "\n",
    "class iiCF(object):\n",
    "    \"\"\"\n",
    "    Item-Item Collaborative Filtering implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Y_data: np.ndarray, k: int = 40, sim_func=cosine_similarity):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        Args:\n",
    "            Y_data (np.ndarray): A 2D array of shape (n_samples, 3) where each row is [user_id, item_id, rating].\n",
    "            k (int): The number of nearest neighbors to consider.\n",
    "            sim_func (function): Similarity function to compute item-item similarity (default: cosine_similarity).\n",
    "        \"\"\"\n",
    "        self.Y_data = Y_data  # User-item interaction data\n",
    "        self.k = k  # Number of neighbors\n",
    "        self.sim_func = sim_func  # Similarity function\n",
    "        self.Ybar = None  # Normalized rating data\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1  # Number of users\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1  # Number of items\n",
    "        self.mu = None  # Item mean ratings\n",
    "        self.S = None  # Item-item similarity matrix\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Prepares the data by normalizing the ratings, creating a sparse matrix, and computing the similarity matrix.\n",
    "        \"\"\"\n",
    "        # Extract item IDs from data\n",
    "        items = self.Y_data[:, 1]\n",
    "\n",
    "        # Copy and normalize the ratings\n",
    "        self.Ybar = self.Y_data.copy()\n",
    "        self.mu = np.zeros(self.n_items)\n",
    "\n",
    "        # Compute mean rating for each item\n",
    "        self.mu = np.bincount(items.astype(int), weights=self.Y_data[:, 2]) / np.bincount(items.astype(int))\n",
    "        self.mu = np.nan_to_num(self.mu)  # Replace NaNs with 0 for items with no ratings\n",
    "\n",
    "        # Normalize ratings by subtracting item means\n",
    "        self.Ybar[:, 2] = self.Y_data[:, 2] - self.mu[items.astype(int)]\n",
    "\n",
    "        # Create a sparse matrix representation of the normalized ratings\n",
    "        self.Ybar = sparse.coo_matrix(\n",
    "            (self.Ybar[:, 2], (self.Ybar[:, 0], self.Ybar[:, 1])),\n",
    "            shape=(self.n_users, self.n_items)\n",
    "        ).tocsr()\n",
    "\n",
    "        # Compute item-item similarity matrix\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def predict_rating(self, user_id: int, item_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Predict the rating of a specific user for a specific item.\n",
    "        Args:\n",
    "            user_id (int): ID of the user.\n",
    "            item_id (int): ID of the item.\n",
    "        Returns:\n",
    "            float: Predicted rating for the given user and item.\n",
    "        \"\"\"\n",
    "        # Find all items rated by the target user\n",
    "        user_ratings = np.where(self.Y_data[:, 0] == user_id)[0].astype(int)\n",
    "        items_rated_by_user = self.Y_data[user_ratings, 1].astype(int)\n",
    "\n",
    "        # Similarity of the target item with items rated by the user\n",
    "        sim_scores = self.S[item_id, items_rated_by_user]\n",
    "\n",
    "        # Get the k most similar items\n",
    "        nearest_neighbors = np.argsort(sim_scores)[-self.k:]  # Top-k similarities\n",
    "        nearest_sim_scores = sim_scores[nearest_neighbors]  # Similarities of nearest neighbors\n",
    "        ratings_by_neighbors = self.Ybar[items_rated_by_user[nearest_neighbors], user_id]  # Ratings by neighbors\n",
    "\n",
    "        # Compute weighted average prediction\n",
    "        eps = 1e-8  # Small number to avoid division by zero\n",
    "        prediction = (ratings_by_neighbors * nearest_sim_scores).sum() / (np.abs(nearest_sim_scores).sum() + eps)\n",
    "\n",
    "        # Add the item's mean rating back\n",
    "        return prediction + self.mu[item_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating base:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1         1       5       874965758\n",
      "1        1         2       3       876893171\n",
      "2        1         3       4       878542960\n",
      "3        1         4       3       876893119\n",
      "4        1         5       3       889751712 \n",
      "\n",
      "Rating test:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1         6       5       887431973\n",
      "1        1        10       3       875693118\n",
      "2        1        12       5       878542960\n",
      "3        1        14       5       874965706\n",
      "4        1        17       3       875073198 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "rating_base = pd.read_csv('ml-100k/u1.base', sep='\\t', names=r_cols)\n",
    "rating_test = pd.read_csv('ml-100k/u1.test', sep='\\t', names=r_cols)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Rating base:\\n', rating_base.head(), '\\n')\n",
    "print('Rating test:\\n', rating_test.head(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running User-User Collaborative Filtering...\n",
      "User-User CF, RMSE = 0.981525986899648\n"
     ]
    }
   ],
   "source": [
    "# Convert data to numpy arrays\n",
    "rate_train = rating_base.to_numpy()\n",
    "rate_test = rating_test.to_numpy()\n",
    "\n",
    "# Transform user and item indices to start from 0 (required for matrix operations)\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Train and evaluate User-User Collaborative Filtering\n",
    "print(\"Running User-User Collaborative Filtering...\")\n",
    "rs = uuCF(rate_train, k=40)\n",
    "rs.fit()\n",
    "\n",
    "# Calculate RMSE for User-User CF\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0  # Squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.predict_rating(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2]) ** 2\n",
    "\n",
    "RMSE = np.sqrt(SE / n_tests)\n",
    "print(f'User-User CF, RMSE = {RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Item-Item Collaborative Filtering (iiCF)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'list' argument must have no negative elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning Item-Item Collaborative Filtering (iiCF)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m rs_ii \u001b[38;5;241m=\u001b[39m iiCF(rate_train, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mrs_ii\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate RMSE for Item-Item CF using iiCF\u001b[39;00m\n\u001b[0;32m     15\u001b[0m n_tests \u001b[38;5;241m=\u001b[39m rate_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[4], line 122\u001b[0m, in \u001b[0;36miiCF.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_items)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Compute mean rating for each item\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(items\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu)  \u001b[38;5;66;03m# Replace NaNs with 0 for items with no ratings\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Normalize ratings by subtracting item means\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'list' argument must have no negative elements"
     ]
    }
   ],
   "source": [
    "# Transform data back to original format for Item-Item CF\n",
    "rate_train = rating_base.to_numpy()\n",
    "rate_test = rating_test.to_numpy()\n",
    "\n",
    "# Transform user and item indices to start from 0 (required for matrix operations)\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Train and evaluate Item-Item Collaborative Filtering with the new iiCF class\n",
    "print(\"\\nRunning Item-Item Collaborative Filtering (iiCF)...\")\n",
    "rs_ii = iiCF(rate_train, k=40)\n",
    "rs_ii.fit()\n",
    "\n",
    "# Calculate RMSE for Item-Item CF using iiCF\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0  # Squared error\n",
    "for n in tqdm(range(n_tests), desc=\"Calculating RMSE for iiCF\", unit=\"test\"):\n",
    "    pred = rs_ii.predict_rating(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2]) ** 2\n",
    "\n",
    "RMSE_ii = np.sqrt(SE / n_tests)\n",
    "print(f'Item-Item CF (iiCF), RMSE = {RMSE_ii}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
