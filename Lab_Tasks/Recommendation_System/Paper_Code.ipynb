{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import openai\n",
    "import random \n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--length_limit', type=int, default=8, help='')\n",
    "parser.add_argument('--num_cand', type=int, default=19, help='')\n",
    "parser.add_argument('--random_seed', type=int, default=2023, help='')\n",
    "parser.add_argument('--api_key', type=str, default=\"sk-\", help=\"\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "rseed = args.random_seed\n",
    "random.seed(rseed)\n",
    "\n",
    "def read_json(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def write_json(data, file):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "data_ml_100k = read_json(\"./ml_100k.json\")\n",
    "\n",
    "# print (data_ml_100k[0][0])\n",
    "# print (data_ml_100k[0][1])\n",
    "# print (len(data_ml_100k))\n",
    "\n",
    "\n",
    "open_ai_keys = [args.api_key]\n",
    "open_ai_keys_index = 0\n",
    "openai.api_key = open_ai_keys[open_ai_keys_index]\n",
    "\n",
    "\n",
    "u_item_dict = {}\n",
    "u_item_p = 0\n",
    "for elem in data_ml_100k:\n",
    "    seq_list = elem[0].split(' | ')\n",
    "    for movie in seq_list:\n",
    "        if movie not in u_item_dict:\n",
    "            u_item_dict[movie] = u_item_p\n",
    "            u_item_p +=1\n",
    "print (len(u_item_dict))\n",
    "u_item_len = len(u_item_dict)\n",
    "\n",
    "user_list = []\n",
    "for i, elem in  enumerate(data_ml_100k):\n",
    "    item_hot_list = [0 for ii in range(u_item_len)]\n",
    "    seq_list = elem[0].split(' | ')\n",
    "    for movie in seq_list:\n",
    "        item_pos = u_item_dict[movie]\n",
    "        item_hot_list[item_pos] = 1\n",
    "    user_list.append(item_hot_list)\n",
    "user_matrix = np.array(user_list)\n",
    "user_matrix_sim = np.dot(user_matrix, user_matrix.transpose())\n",
    "\n",
    "\n",
    "pop_dict = {}\n",
    "for elem in data_ml_100k:\n",
    "    # elem = data_ml_100k[i]\n",
    "    seq_list = elem[0].split(' | ')\n",
    "    for movie in seq_list:\n",
    "        if movie not in pop_dict:\n",
    "              pop_dict[movie] = 0\n",
    "        pop_dict[movie] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "i_item_dict = {}\n",
    "i_item_id_list = []\n",
    "i_item_user_dict = {}\n",
    "i_item_p = 0\n",
    "for i, elem in  enumerate(data_ml_100k):\n",
    "    seq_list = elem[0].split(' | ')\n",
    "    for movie in seq_list:\n",
    "        if movie not in i_item_user_dict:\n",
    "            item_hot_list = [0. for ii in range(len(data_ml_100k))]\n",
    "            i_item_user_dict[movie] = item_hot_list\n",
    "            i_item_dict[movie] = i_item_p\n",
    "            i_item_id_list.append(movie)\n",
    "            i_item_p+=1\n",
    "#         item_pos = item_dict[movie]\n",
    "        i_item_user_dict[movie][i] += 1\n",
    "#     user_list.append(item_hot_list)\n",
    "i_item_s_list = []\n",
    "for item in i_item_id_list:\n",
    "    i_item_s_list.append(i_item_user_dict[item])\n",
    "#     print (sum(item_user_dict[item]))\n",
    "item_matrix = np.array(i_item_s_list)\n",
    "item_matrix_sim = np.dot(item_matrix, item_matrix.transpose())\n",
    "\n",
    "id_list =list(range(0,len(data_ml_100k)))\n",
    "\n",
    "\n",
    "\n",
    "### user filtering\n",
    "def sort_uf_items(target_seq, us, num_u, num_i):\n",
    "\n",
    "    candidate_movies_dict = {} \n",
    "    sorted_us = sorted(list(enumerate(us)), key=lambda x: x[-1], reverse=True)[:num_u]\n",
    "    dvd = sum([e[-1] for e in sorted_us])\n",
    "    for us_i, us_v in sorted_us:\n",
    "        us_w = us_v * 1.0/dvd\n",
    "#         print (us_i)\n",
    "        us_elem = data_ml_100k[us_i]\n",
    "#         print (us_elem[0])\n",
    "#         assert 1==0\n",
    "        us_seq_list = us_elem[0].split(' | ')#+[us_elem[1]]\n",
    "\n",
    "        for us_m in us_seq_list:\n",
    "#             print (f\"{us_m} not in {target_seq}, {us_m not in target_seq}\")\n",
    "#             break\n",
    "\n",
    "            if us_m not in target_seq:\n",
    "                if us_m not in candidate_movies_dict:\n",
    "                    candidate_movies_dict[us_m] = 0.\n",
    "                candidate_movies_dict[us_m]+=us_w\n",
    "                \n",
    "#         assert 1==0\n",
    "                \n",
    "    candidate_pairs = list(sorted(candidate_movies_dict.items(), key=lambda x:x[-1], reverse=True))\n",
    "#     print (candidate_pairs)\n",
    "    candidate_items = [e[0] for e in candidate_pairs][:num_i]\n",
    "    return candidate_items\n",
    "\n",
    "\n",
    "### item filtering\n",
    "def soft_if_items(target_seq, num_i, total_i, item_matrix_sim, item_dict):\n",
    "    candidate_movies_dict = {} \n",
    "    for movie in target_seq:\n",
    "#         print('ttt:',movie)\n",
    "        sorted_is = sorted(list(enumerate(item_matrix_sim[item_dict[movie]])), key=lambda x: x[-1], reverse=True)[:num_i]\n",
    "        for is_i, is_v in sorted_is:\n",
    "            s_item = i_item_id_list[is_i]\n",
    "            \n",
    "            if s_item not in target_seq:\n",
    "                if s_item not in candidate_movies_dict:\n",
    "                    candidate_movies_dict[s_item] = 0.\n",
    "                candidate_movies_dict[s_item] += is_v\n",
    "#             print (item_id_list[is_i], candidate_movies_dict)\n",
    "    candidate_pairs = list(sorted(candidate_movies_dict.items(), key=lambda x:x[-1], reverse=True))\n",
    "#     print (candidate_pairs)\n",
    "    candidate_items = [e[0] for e in candidate_pairs][:total_i]\n",
    "#     print (candidate_items)\n",
    "    return candidate_items\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "In order to economize, our initial step is to identify user sequences that exhibit a high probability of obtaining accurate predictions from GPT-3.5 based on their respective candidates. \n",
    "Subsequently, we proceed to utilize the GPT-3.5 API to generate predictions for these promising user sequences.\n",
    "'''\n",
    "results_data_15 = []\n",
    "length_limit = args.length_limit\n",
    "num_u= 12\n",
    "total_i = args.num_cand\n",
    "count = 0\n",
    "total = 0\n",
    "cand_ids = []\n",
    "for i in id_list[:1000]:\n",
    "    elem = data_ml_100k[i]\n",
    "    seq_list = elem[0].split(' | ')\n",
    "    \n",
    "    candidate_items = sort_uf_items(seq_list, user_matrix_sim[i], num_u=num_u, num_i=total_i)\n",
    "    \n",
    "#     print (elem[-1], '-',seq_list[-1])\n",
    "\n",
    "    if elem[-1] in candidate_items:\n",
    "#         print ('HIT: 1')\n",
    "        count += 1\n",
    "        cand_ids.append(i)\n",
    "    else:\n",
    "        pass\n",
    "#         print ('HIT: 0')\n",
    "    total +=1\n",
    "print (f'count/total:{count}/{total}={count*1.0/total}')\n",
    "print ('-----------------\\n')\n",
    "\n",
    "\n",
    "temp_1 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "temp_2 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: {}.\n",
    "Step 2: Selecting the most featured movies from the watched movies according to my preferences (Format: [no. a watched movie.]). \n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "temp_3 = \"\"\"\n",
    "Candidate Set (candidate movies): {}.\n",
    "The movies I have watched (watched movies): {}.\n",
    "Step 1: What features are most important to me when selecting movies (Summarize my preferences briefly)? \n",
    "Answer: {}.\n",
    "Step 2: Selecting the most featured movies (at most 5 movies) from the watched movies according to my preferences in descending order (Format: [no. a watched movie.]). \n",
    "Answer: {}.\n",
    "Step 3: Can you recommend 10 movies from the Candidate Set similar to the selected movies I've watched (Format: [no. a watched movie - a candidate movie])?.\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "results_data = []\n",
    "for i in cand_ids[:]:#[:10] + cand_ids[49:57] + cand_ids[75:81]:\n",
    "    elem = data_ml_100k[i]\n",
    "    seq_list = elem[0].split(' | ')[::-1]\n",
    "    \n",
    "    candidate_items = sort_uf_items(seq_list, user_matrix_sim[i], num_u=num_u, num_i=total_i)\n",
    "    random.shuffle(candidate_items)\n",
    "\n",
    "    input_1 = temp_1.format(', '.join(candidate_items), ', '.join(seq_list[-length_limit:]))\n",
    "\n",
    "    try_nums = 5\n",
    "    kk_flag = 1\n",
    "    while try_nums:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                      engine=\"text-davinci-003\",\n",
    "                      prompt=input_1,\n",
    "                      max_tokens=512,\n",
    "                      temperature=0,\n",
    "                      top_p=1,\n",
    "                      frequency_penalty=0,\n",
    "                      presence_penalty=0,\n",
    "                      n = 1,\n",
    "                  )\n",
    "            try_nums = 0\n",
    "            kk_flag = 1\n",
    "        except Exception as e:\n",
    "            if 'exceeded your current quota' in str(e):\n",
    "\n",
    "                # open_ai_keys_index +=1\n",
    "                openai.api_key = open_ai_keys[open_ai_keys_index]\n",
    "            time.sleep(1) \n",
    "            try_nums = try_nums-1\n",
    "            kk_flag = 0\n",
    "\n",
    "    if kk_flag == 0:\n",
    "        time.sleep(5) \n",
    "        response = openai.Completion.create(\n",
    "                      engine=\"text-davinci-003\",\n",
    "                      prompt=input_1,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0,\n",
    "                      top_p=1,\n",
    "                      frequency_penalty=0,\n",
    "                      presence_penalty=0,\n",
    "                      n = 1,\n",
    "                  )\n",
    "\n",
    "    predictions_1 = response[\"choices\"][0]['text']\n",
    "    \n",
    "    \n",
    "    input_2 = temp_2.format(', '.join(candidate_items), ', '.join(seq_list[-length_limit:]), predictions_1)\n",
    "\n",
    "    try_nums = 5\n",
    "    kk_flag = 1\n",
    "    while try_nums:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                      engine=\"text-davinci-003\",\n",
    "                      prompt=input_2,\n",
    "                      max_tokens=512,\n",
    "                      temperature=0,\n",
    "                      top_p=1,\n",
    "                      frequency_penalty=0,\n",
    "                      presence_penalty=0,\n",
    "                      n = 1,\n",
    "                  )\n",
    "            try_nums = 0\n",
    "            kk_flag = 1\n",
    "        except Exception as e:\n",
    "            if 'exceeded your current quota' in str(e):\n",
    "\n",
    "                # open_ai_keys_index +=1\n",
    "                openai.api_key = open_ai_keys[open_ai_keys_index]\n",
    "            time.sleep(1) \n",
    "            try_nums = try_nums-1\n",
    "            kk_flag = 0\n",
    "\n",
    "    if kk_flag == 0:\n",
    "        time.sleep(5) \n",
    "        response = openai.Completion.create(\n",
    "                      engine=\"text-davinci-003\",\n",
    "                      prompt=input_2,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0,\n",
    "                      top_p=1,\n",
    "                      frequency_penalty=0,\n",
    "                      presence_penalty=0,\n",
    "                      n = 1,\n",
    "                  )\n",
    "\n",
    "    predictions_2 = response[\"choices\"][0]['text']\n",
    "    \n",
    "    \n",
    "    input_3 = temp_3.format(', '.join(candidate_items), ', '.join(seq_list[-length_limit:]), predictions_1, predictions_2)\n",
    "\n",
    "    try_nums = 5\n",
    "    kk_flag = 1\n",
    "    while try_nums:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                      engine=\"text-davinci-003\",\n",
    "                      prompt=input_3,\n",
    "                      max_tokens=512,\n",
    "                      temperature=0,\n",
    "                      top_p=1,\n",
    "                      frequency_penalty=0,\n",
    "                      presence_penalty=0,\n",
    "                      n = 1,\n",
    "                  )\n",
    "            try_nums = 0\n",
    "            kk_flag = 1\n",
    "        except Exception as e:\n",
    "            if 'exceeded your current quota' in str(e):\n",
    "\n",
    "                # open_ai_keys_index +=1\n",
    "                openai.api_key = open_ai_keys[open_ai_keys_index]\n",
    "            time.sleep(1) \n",
    "            try_nums = try_nums-1\n",
    "            kk_flag = 0\n",
    "\n",
    "    if kk_flag == 0:\n",
    "        time.sleep(5) \n",
    "        response = openai.Completion.create(\n",
    "                      engine=\"text-davinci-003\",\n",
    "                      prompt=input_3,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0,\n",
    "                      top_p=1,\n",
    "                      frequency_penalty=0,\n",
    "                      presence_penalty=0,\n",
    "                      n = 1,\n",
    "                  )\n",
    "\n",
    "    predictions = response[\"choices\"][0]['text']\n",
    "    \n",
    "\n",
    "    hit_=0\n",
    "    if elem[1] in predictions:\n",
    "        count += 1\n",
    "        hit_ = 1\n",
    "    else:\n",
    "        pass\n",
    "    total +=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print (f\"input_1:{input_1}\")\n",
    "    # print (f\"predictions_1:{predictions_1}\\n\")\n",
    "    # print (f\"input_2:{input_2}\")\n",
    "    # print (f\"predictions_2:{predictions_2}\\n\")\n",
    "    # print (f\"input_3:{input_3}\")\n",
    "    print (f\"GT:{elem[1]}\")\n",
    "    print (f\"predictions:{predictions}\")\n",
    "    \n",
    "    # print (f\"GT:{elem[-1]}\")\n",
    "    print (f'PID:{i}; count/total:{count}/{total}={count*1.0/total}\\n')\n",
    "    result_json = {\"PID\": i,\n",
    "                   \"Input_1\": input_1,\n",
    "                   \"Input_2\": input_2,\n",
    "                   \"Input_3\": input_3,\n",
    "                   \"GT\": elem[1],\n",
    "                   \"Predictions_1\": predictions_1,\n",
    "                   \"Predictions_2\": predictions_2,\n",
    "                   \"Predictions\": predictions,\n",
    "                   'Hit': hit_,\n",
    "                   'Count': count,\n",
    "                   'Current_total':total,\n",
    "                   'Hit@10':count*1.0/total}\n",
    "    results_data.append(result_json)\n",
    "\n",
    "    \n",
    "    \n",
    "file_dir = f\"./results_multi_prompting_len{length_limit}_numcand_{total_i}_seed{rseed}.json\"\n",
    "write_json(results_data, file_dir)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
