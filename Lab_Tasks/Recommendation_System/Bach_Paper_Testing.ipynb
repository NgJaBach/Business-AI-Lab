{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "class CollaborativeFiltering:\n",
    "    \"\"\"\n",
    "    Collaborative Filtering class for User-User or Item-Item predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, Y_data: np.ndarray, k: int, sim_func = cosine_similarity, mode='user') -> None:\n",
    "        \"\"\"\n",
    "        Initialize the collaborative filtering model.\n",
    "        \n",
    "        Parameters:\n",
    "        - Y_data: numpy array of shape (n_samples, 3), each row is [entity1_id, entity2_id, rating]\n",
    "        - k: number of nearest neighbors to consider for predictions\n",
    "        - sim_func: similarity function, default is cosine similarity\n",
    "        - mode: 'user' for User-User CF, 'item' for Item-Item CF\n",
    "        \"\"\"\n",
    "        self.Y_data = Y_data\n",
    "        self.k = k\n",
    "        self.sim_func = sim_func\n",
    "        self.Ybar = None\n",
    "        self.mode = mode\n",
    "        if mode == 'user':\n",
    "            self.n_entities = int(np.max(self.Y_data[:, 0])) + 1  # Number of unique users\n",
    "            self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
    "        elif mode == 'item':\n",
    "            self.n_entities = int(np.max(self.Y_data[:, 0])) + 1  # Number of unique items\n",
    "            self.n_users = int(np.max(self.Y_data[:, 1])) + 1\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be 'user' or 'item'\")\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Normalize the data and compute the similarity matrix.\n",
    "        \"\"\"\n",
    "        entities = self.Y_data[:, 0]  # Extract all entity IDs\n",
    "        self.Ybar = self.Y_data.copy()\n",
    "        self.mr = np.zeros((self.n_entities,))\n",
    "\n",
    "        # Normalize ratings for each entity\n",
    "        for e in range(self.n_entities):\n",
    "            ids = np.flatnonzero(entities == e)\n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            self.mr[e] = np.mean(ratings) if ids.size > 0 else 0\n",
    "            self.Ybar[ids, 2] = ratings - self.mr[e]\n",
    "\n",
    "        # Create a sparse matrix\n",
    "        if self.mode == 'user':\n",
    "            self.Ybar = sparse.coo_matrix(\n",
    "                (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])),\n",
    "                shape=(self.n_items, self.n_entities)\n",
    "            ).tocsr()\n",
    "        else:  # mode == 'item'\n",
    "            self.Ybar = sparse.coo_matrix(\n",
    "                (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])),\n",
    "                shape=(self.n_users, self.n_entities)\n",
    "            ).tocsr()\n",
    "\n",
    "        # Compute similarity matrix\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def recommend(self, e: int, num_recommendations: int) -> list:\n",
    "        \"\"\"\n",
    "        Recommend a list of items for UUCF and users for IICF \n",
    "        \n",
    "        Parameters:\n",
    "        - e: the ID of the target\n",
    "        - num_recommendations: number of entities to recommend\n",
    "        \n",
    "        Returns:\n",
    "        - A list of recommended entity IDs\n",
    "        \"\"\"\n",
    "        if self.mode == 'user':\n",
    "            # Find the similar users to the target user\n",
    "            sim = self.S[e, :]\n",
    "            nearest_users = np.argsort(sim)[-self.k:]\n",
    "            # Get the items these similar users rated, and recommend the most popular ones\n",
    "            recommended_items = set()\n",
    "            for user in nearest_users:\n",
    "                user_ratings = self.Y_data[self.Y_data[:, 0] == user]\n",
    "                for item_id in user_ratings[:, 1]:\n",
    "                    recommended_items.add(item_id)\n",
    "            # Return the top N recommendations\n",
    "            return list(recommended_items)[:num_recommendations]\n",
    "        else:  # mode == 'item'\n",
    "            sim = self.S[e, :]\n",
    "            nearest_items = np.argsort(sim)[-self.k:]\n",
    "            # Return the most similar items (excluding the target item itself)\n",
    "            recommended_items = [item for item in nearest_items if item != e]\n",
    "            return recommended_items[:num_recommendations]\n",
    "        \n",
    "    def evaluate_recommendations(self, test_data, num_recommendations: int):\n",
    "        hits = 0\n",
    "        for user_id, item_id, rating in test_data:\n",
    "            recommendations = self.recommend(user_id, num_recommendations)\n",
    "            if item_id in recommendations:\n",
    "                hits += 1\n",
    "        hit_ratio = hits / len(test_data)\n",
    "        print(f\"Hit Ratio: {hit_ratio:.4f}\")\n",
    "\n",
    "\n",
    "# Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "rating_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols)\n",
    "rating_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Rating base:\\n', rating_base.head(), '\\n')\n",
    "print('Rating test:\\n', rating_test.head(), '\\n')\n",
    "\n",
    "rate_train = rating_base.to_numpy()\n",
    "rate_test = rating_test.to_numpy()\n",
    "\n",
    "# Constants\n",
    "k_neighbors = 40\n",
    "n_recommendations = 10\n",
    "\n",
    "# indices start from 0 for User-User CF\n",
    "rate_train_uu = rate_train.copy()\n",
    "rate_test_uu = rate_test.copy()\n",
    "rate_train_uu[:, :2] -= 1\n",
    "rate_test_uu[:, :2] -= 1\n",
    "\n",
    "# indices start from 0 for Item-Item CF (swap user and item)\n",
    "rate_train_ii = rate_train[:, [1, 0, 2]].copy()\n",
    "rate_test_ii = rate_test[:, [1, 0, 2]].copy()\n",
    "rate_train_ii[:, :2] -= 1\n",
    "rate_test_ii[:, :2] -= 1\n",
    "\n",
    "# User-User CF\n",
    "print(\"Evaluating User-User CF with generic class...\")\n",
    "cf_user = CollaborativeFiltering(rate_train_uu, k_neighbors, mode='user')\n",
    "cf_user.fit()\n",
    "\n",
    "n_tests_uu = rate_test_uu.shape[0]\n",
    "SE_user = 0\n",
    "for n in range(n_tests_uu):\n",
    "    pred = cf_user.pred(int(rate_test_uu[n, 0]), int(rate_test_uu[n, 1]))\n",
    "    SE_user += (pred - rate_test_uu[n, 2]) ** 2 \n",
    "\n",
    "# Item-Item CF\n",
    "print(\"Evaluating Item-Item CF with generic class...\")\n",
    "cf_item = CollaborativeFiltering(rate_train_ii, k_neighbors, mode='item')\n",
    "cf_item.fit()\n",
    "\n",
    "n_tests_ii = rate_test_ii.shape[0]\n",
    "SE_item = 0\n",
    "for n in range(n_tests_ii):\n",
    "    pred = cf_item.pred(int(rate_test_ii[n, 0]), int(rate_test_ii[n, 1]))\n",
    "    SE_item += (pred - rate_test_ii[n, 2]) ** 2 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
