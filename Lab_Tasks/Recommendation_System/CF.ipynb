{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood-based Collaborative Filtering example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from typing import Callable\n",
    "\n",
    "class UserUserCF:\n",
    "    \"\"\"\n",
    "    User-User Collaborative Filtering class for predicting user ratings of items\n",
    "    based on similar users' ratings.\n",
    "    \"\"\"\n",
    "    def __init__(self, Y_data: np.ndarray, k: int, sim_func = cosine_similarity) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the collaborative filtering model.\n",
    "        \n",
    "        Parameters:\n",
    "        - Y_data: numpy array of shape (n_samples, 3), each row is [user_id, item_id, rating]\n",
    "        - k: number of nearest neighbors to consider for predictions\n",
    "        - sim_func: similarity function, default is cosine similarity\n",
    "        \"\"\"\n",
    "        self.Y_data = Y_data  # Original data (user, item, rating)\n",
    "        self.k = k  # Number of neighbors\n",
    "        self.sim_func = sim_func  # Similarity function\n",
    "        self.Ybar = None  # Normalized rating matrix\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1  # Number of unique users\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1  # Number of unique items\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Normalize the data and compute the user-user similarity matrix.\n",
    "        \"\"\"\n",
    "        users = self.Y_data[:, 0]  # Extract all user IDs\n",
    "        self.Ybar = self.Y_data.copy()  # Make a copy of the data for normalization\n",
    "        self.mu = np.zeros((self.n_users,))  # Mean rating for each user\n",
    "\n",
    "        # Normalize ratings for each user\n",
    "        for n in range(self.n_users):\n",
    "            ids = np.flatnonzero(users == n)  # Ratings made by user n\n",
    "            ratings = self.Y_data[ids, 2]  # User's ratings\n",
    "            self.mu[n] = np.mean(ratings) if ids.size > 0 else 0  # Mean rating or 0 if no ratings\n",
    "            self.Ybar[ids, 2] = ratings - self.mu[n]  # Subtract mean rating\n",
    "\n",
    "        # Create a sparse matrix of normalized ratings\n",
    "        self.Ybar = sparse.coo_matrix(\n",
    "            (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])),\n",
    "            shape=(self.n_items, self.n_users)\n",
    "        ).tocsr()\n",
    "\n",
    "        # Compute user-user similarity matrix\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def pred(self, u: int, i: int) -> float:\n",
    "        \"\"\"\n",
    "        Predict the rating of user u for item i.\n",
    "        \n",
    "        Parameters:\n",
    "        - u: user ID\n",
    "        - i: item ID\n",
    "        \n",
    "        Returns:\n",
    "        - Predicted rating\n",
    "        \"\"\"\n",
    "        # Find all users who rated item i\n",
    "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\n",
    "        users_rated_i = self.Y_data[ids, 0].astype(np.int32)  # Users who rated item i\n",
    "\n",
    "        # Similarities between user u and users who rated item i\n",
    "        sim = self.S[u, users_rated_i]\n",
    "        # Select k most similar users\n",
    "        nns = np.argsort(sim)[-self.k:]\n",
    "        nearest_s = sim[nns]  # Similarities of the nearest neighbors\n",
    "        r = self.Ybar[i, users_rated_i[nns]]  # Ratings from the nearest neighbors\n",
    "\n",
    "        # Compute the predicted rating\n",
    "        eps = 1e-8  # Small value to prevent division by zero\n",
    "        return (r * nearest_s).sum() / (np.abs(nearest_s).sum() + eps) + self.mu[u]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating base:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1         1       5       874965758\n",
      "1        1         2       3       876893171\n",
      "2        1         3       4       878542960\n",
      "3        1         4       3       876893119\n",
      "4        1         5       3       889751712 \n",
      "\n",
      "Rating test:\n",
      "    user_id  movie_id  rating  unix_timestamp\n",
      "0        1        20       4       887431883\n",
      "1        1        33       4       878542699\n",
      "2        1        61       4       878542420\n",
      "3        1       117       3       874965739\n",
      "4        1       155       2       878542201 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "rating_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols)\n",
    "rating_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print('Rating base:\\n', rating_base.head(), '\\n')\n",
    "print('Rating test:\\n', rating_test.head(), '\\n')\n",
    "\n",
    "rate_train = rating_base.to_numpy()\n",
    "rate_test = rating_test.to_numpy()\n",
    "\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-user CF, RMSE = 0.9766140289287265\n"
     ]
    }
   ],
   "source": [
    "rs = UserUserCF(rate_train, k = 40)\n",
    "rs.fit()\n",
    " \n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2])**2 \n",
    "\n",
    "RMSE = np.sqrt(SE/n_tests)\n",
    "print('User-user CF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-item CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-item CF, RMSE = 0.9688460838682366\n"
     ]
    }
   ],
   "source": [
    "rate_train = rate_train[:, [1, 0, 2]]\n",
    "rate_test  = rate_test[:, [1, 0, 2]]\n",
    "\n",
    "rs = UserUserCF(rate_train, k = 40)\n",
    "rs.fit()\n",
    "\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2])**2 \n",
    "\n",
    "RMSE = np.sqrt(SE/n_tests)\n",
    "print('Item-item CF, RMSE =', RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
